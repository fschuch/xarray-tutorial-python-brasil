{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://xarray.pydata.org/en/stable/_static/dataset-diagram-logo.png\" align=\"right\" width=\"30%\">\n",
    "\n",
    "# Introdução ao Dask\n",
    "\n",
    "Nesta lição, discutiremos os fundamentos do Dask. Nossos objetivos de aprendizagem são conforme segue. Ao final da lição, seremos capazes de:\n",
    "\n",
    "- Identificar e descrever coleções Dask (Array, DataFrame) e Schedulers;\n",
    "- Trabalhar com o Dask Array da mesma maneira que trabalharia com um NumPy;\n",
    "- Compreender algumas das compensações em torno do tamanho do *chunk* (pedaço, fração, fatia), forma do *chunk* e sobrecarga computacional;\n",
    "- Implantar um *Dask Distributed Cluster* local e acessar o painel de diagnóstico.\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "1. [**O que é Dask?**](#O-que-é-Dask?)\n",
    "1. [**Estruturas de dados em Dask**](#Estruturas-de-dados-em-Dask)\n",
    "1. [**Paralelismo usando o agendador dask.distributed**](#Paralelismo-usando-o-agendador-dask.distributed)\n",
    "1. [**Análise e diagnóstico usando o painel Dask**](#Análise-e-diagnóstico-usando-o-painel-Dask)\n",
    "1. [**Clusters Dask distribuídos para ambientes HPC e nuvem**](#Clusters-Dask-distribuídos-para-ambientes-HPC-e-nuvem)\n",
    "\n",
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\" \n",
    "     width=\"30%\" \n",
    "     align=right\n",
    "     alt=\"Dask logo\">\n",
    "\n",
    "## O que é Dask?\n",
    "\n",
    "Dask é uma biblioteca de computação paralela flexível para computação analítica. Dask\n",
    "fornece agendamento dinâmico de tarefas paralelas e estruturas de dados (*big-data*) de alto nível como `dask.array` e` dask.dataframe`, e um amplo pacote com opções para desenvolvimento. A documentação do Dask pode ser encontrada aqui: https://docs.dask.org/en/latest/\n",
    "\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask-overview.svg\" \n",
    "     width=\"75%\" \n",
    "     align=center\n",
    "     alt=\"Dask overview\">\n",
    "\n",
    "## Configuração rápida\n",
    "\n",
    "A fim de exemplificar sua utilização neste notebook, usaremos um cluster Dask para gerenciar nosso cálculos. A célula a seguir configura um Cluster local simples. Vamos cobrir os agendadores e clusters em Dask posteriormente neste notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&#128070</p> Clique no link Dashboard acima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estruturas de dados em Dask\n",
    "\n",
    "Dask inclui três estruturas especiais para cálculo paralelo:\n",
    "\n",
    "- [Dask Array](https://docs.dask.org/en/latest/array.html): Versão paralela de arranjos NumPy;\n",
    "- [Dask DataFrame](https://docs.dask.org/en/latest/dataframe.html): Versão paralela de tabelas (*DataFrames*) Pandas;\n",
    "- [Dask Bag](https://docs.dask.org/en/latest/bag.html): Versão paralela de listas em Python.\n",
    "\n",
    "Xarray contém uma interface primária com os objetos *Dask Array*, por hora focaremos apenas nesse ponto. Você pode descobrir mais sobre as demais interfaces de usuário do Dask\n",
    "[aqui](https://docs.dask.org/en/latest/user-interfaces.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranjos Dask\n",
    "\n",
    "*Dask Array* implementa um subconjunto da interface NumPy `ndarray` que rastrei as tarefas e divide o grande arranjo em muitos pequenos arranjos.\n",
    "**Isso nos permite calcular em arranjos maiores que a memória usando múltiplos núcleos.**\n",
    "as tarefas são coordenadas usando gráficos Dask.\n",
    "As matrizes de Dask também são **preguiçosos / inertes (_lazy_)**, o que significa que\n",
    "elas não são avaliadas até que você peça explicitamente um resultado usando o método `compute`.\n",
    "\n",
    "Se quisermos criar um array NumPy com todas as entradas unitárias, fazemos assim:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shape = (1000, 4000)\n",
    "ones_np = np.ones(shape)\n",
    "ones_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa matriz contém exatamente 32 MB de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.1f MB\" % (ones_np.nbytes / 1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos criar o mesmo array usando a interface de array do Dask:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "ones = da.ones(shape)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionou! Mas ainda não dissemos ao Dask como dividir (ou fragmentar) a matriz, então\n",
    "não é otimizado para computação paralela.\n",
    "\n",
    "Uma diferença crucial com Dask é que devemos especificar o argumento `chunks`.\n",
    "\"*Chunks*\" (ou pedaços) descreve como a matriz é dividida em muitas submatrizes.\n",
    "\n",
    "![Dask Arrays](http://dask.pydata.org/en/latest/_images/dask-array-black-text.svg)\n",
    "_Fonte:\n",
    "[Dask Array Documentation](http://dask.pydata.org/en/latest/array-overview.html)_\n",
    "\n",
    "Existem [várias maneiras de especificar essa fragmentação] (http://dask.pydata.org/en/latest/array-creation.html#chunks). Nesta aula, usaremos a formulação em blocos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_shape = (1000, 1000)\n",
    "ones = da.ones(shape, chunks=chunk_shape)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que vemos apenas uma representação simbólica da matriz, incluindo sua\n",
    "forma, tipo de dados e tamanho do bloco. Nenhum dado foi gerado ainda. Quando invocamos\n",
    "`.compute ()` em uma matriz Dask, a computação é acionada e a matriz dask\n",
    "torna-se uma matriz numpy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender o que aconteceu quando chamamos `.compute()`, podemos\n",
    "visualize o *gráfico* Dask, as operações simbólicas que compõem o arranjo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso array possui quatro blocos. Para gerá-lo, Dask chama `np.ones` quatro vezes e\n",
    "em seguida, concatena isso em um array.\n",
    "\n",
    "Em vez de carregar imediatamente uma matriz Dask (que coloca todos os dados na RAM),\n",
    "é mais comum reduzir os dados de alguma forma. Por exemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_ones = ones.sum()\n",
    "sum_of_ones.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Modifique o tamanho do *chunk* (ou sua forma) no array `ones` e visualize as mudanças no gráfico Dask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos a estratégia de Dask para encontrar a soma. Este exemplo simples ilustra\n",
    "a beleza do Dask: ele projeta automaticamente um algoritmo apropriado para customização\n",
    "operações com big data.\n",
    "\n",
    "Se tornarmos nossa operação mais complexa, o gráfico ficará mais complexo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_calculation = (ones * ones[::-1, ::-1]).mean()\n",
    "fancy_calculation.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Um cálculo maior\n",
    "\n",
    "Os exemplos acima foram exemplos didáticos; os dados (32 MB) provavelmente não são grandes\n",
    "o suficiente para justificar o uso de Dask.\n",
    "\n",
    "Podemos torná-lo muito maior!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigshape = (200000, 4000)\n",
    "big_ones = da.ones(bigshape, chunks=chunk_shape)\n",
    "big_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.1f MB\" % (big_ones.nbytes / 1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de dados tem **6,4 GB**, em vez de 32 MB! Isso é provavelmente próximo ou maior do que a quantidade de RAM disponível que você tem em seu computador. Mesmo assim,\n",
    "Dask não tem problema em trabalhar nisso.\n",
    "\n",
    "_Não tente `.visualize()` nesse array!_\n",
    "\n",
    "Ao fazer um grande cálculo, o dask também tem algumas ferramentas para nos ajudar a entender o que está acontecendo sob o capô. Vamos observar o painel novamente enquanto fazemos uma computação maior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_calc = (big_ones * big_ones[::-1, ::-1]).mean()\n",
    "\n",
    "result = big_calc.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução\n",
    "\n",
    "Todos os métodos NumPy usuais funcionam em arrays Dask. Você também pode aplicar funções NumPy diretamente para um array dask e permanecerá preguiçoso (*lazy*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_ones_reduce = (np.cos(big_ones) ** 2).mean(axis=1)\n",
    "big_ones_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plotagem também ativa a computação, uma vez que precisamos dos valores reais:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(big_ones_reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paralelismo usando o agendador dask.distributed\n",
    "\n",
    "Na [primeira célula](#Configuracao-rapida) desse notebook, iniciamos um cliente Dask Cluster local. Nós pulamos alguns detalhes importantes lá que iremos\n",
    "detalhar agora.\n",
    "\n",
    "### Agendadores (*Schedulers*) Dask\n",
    "\n",
    "O Dask _Schedulers_ orquestrar as atividades nos gráficos de tarefas para que elas possam\n",
    "ser executadas em paralelo. _Como_ eles funcionam em paralelo, porém, é determinado por qual _Scheduler_ você escolhe.\n",
    "\n",
    "Existem 3 agendadores _locais_:\n",
    "\n",
    "- **Single-Thread Local:** Para depuração, análise e diagnóstico de problemas;\n",
    "- **Multi-threaded:** Usando o pacote integrado do Python `threading` (o padrão\n",
    "   para todas as operações Dask, exceto `Bags`);\n",
    "- **Multi-processo:** Usando o pacote integrado do Python `multiprocessing` (o padrão para Dask `Bags`).\n",
    "\n",
    "e 1 agendador _distribuído_, sobre o qual falaremos mais tarde:\n",
    "\n",
    "- **Distributed:** Usando o módulo `dask.distributed` (que usa [`tornado`](https://www.tornadoweb.org/en/stable/) para comunicação sobre TCP). O agendador distribuído usa um `Cluster` para gerenciar a comunicação entre o agendador e os \"trabalhadores\". Isso é descrito na próxima seção.\n",
    "\n",
    "### Distributed Clusters (http://distributed.dask.org/)\n",
    "\n",
    "- `LocalCluster` - Cria um `Cluster` que pode ser executado localmente. Cada `Cluster` inclui um `Scheduler` e `Worker`s.\n",
    "- `Client` - Conecta-se e direciona a computação em um `Cluster` distribuído.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise e diagnóstico usando o painel Dask\n",
    "\n",
    "Você deve se lembrar de que abrimos um url para o painel do Dask:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O painel de controle do agendador distribuído Dask fornece uma ferramenta incrivelmente valiosa para obter insights sobre o desempenho de seu cálculo e o cluster como um todo. No painel, você verá uma série de informações:\n",
    "\n",
    "- _Status_: Visão geral do estado atual do planejador, incluindo o fluxo de tarefas ativas, progresso, memória por trabalhador e o número de tarefas por trabalhador;\n",
    "- _Workers_: A guia workers (*trabalhadores*) permite que você rastreie o uso da CPU e da memória por trabalhador;\n",
    "- _Sistema_: Rastreamento ao vivo de recursos do sistema, como CPU, memória, largura de banda e descritores de arquivos;\n",
    "- _Perfil_: Perfil estatístico refinado\n",
    "- _Info_: Status e registros do trabalhador.\n",
    "\n",
    "Outra ferramenta de diagnóstico útil é o relatório de desempenho estático do Dask. Isso lhe permite salvar um relatório, incluindo o fluxo de tarefas, perfis de trabalho, etc. para todos ou uma parte específica de um fluxo de trabalho. Abaixo está um exemplo de como você criaria tal relatório:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import performance_report\n",
    "\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    big_calc.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Novamente, vamos modificar o tamanho do bloco em `big_ones` (visando ~100MB). Como é que\n",
    "_Relatório de desempenho_ mudou com um tamanho de bloco maior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "with performance_report(filename=\"dask-report-large-chunk.html\"):\n",
    "    big_calc.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters Dask distribuídos para ambientes HPC e nuvem\n",
    "\n",
    "Dask pode ser implantado em infraestrutura distribuída, como um sistema HPC (computação de alto desempenho) ou um sistema de computação na nuvem. Há um ecossistema crescente de projetos de implantação de Dask que facilitam a implantação e o dimensionamento de clusters Dask em uma ampla variedade de sistemas de computação.\n",
    "\n",
    "### HPC\n",
    "\n",
    "#### Dask Jobqueue (https://jobqueue.dask.org/)\n",
    "\n",
    "- `dask_jobqueue.PBSCluster`\n",
    "- `dask_jobqueue.SlurmCluster`\n",
    "- `dask_jobqueue.LSFCluster`\n",
    "- etc.\n",
    "\n",
    "#### Dask MPI (https://mpi.dask.org/)\n",
    "\n",
    "- `dask_mpi.initialize`\n",
    "\n",
    "### Cloud\n",
    "\n",
    "#### Dask Kubernetes (https://kubernetes.dask.org/)\n",
    "\n",
    "- `dask_kubernetes.KubeCluster`\n",
    "\n",
    "#### Dask Cloud Provider (https://cloudprovider.dask.org)\n",
    "\n",
    "- `dask_cloudprovider.FargateCluster`\n",
    "- `dask_cloudprovider.ECSCluster`\n",
    "- `dask_cloudprovider.ECSCluster`\n",
    "\n",
    "#### Dask Gateway (https://gateway.dask.org/)\n",
    "\n",
    "- `dask_gateway.GatewayCluster`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_Nota: Partes desse notebook vêm das seguintes fontes:_\n",
    "\n",
    "- https://github.com/pangeo-data/pangeo-tutorial\n",
    "- https://github.com/rabernat/research_computing\n",
    "- https://github.com/dask/dask-examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
